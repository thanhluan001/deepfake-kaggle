{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Kernel Demo II\n",
    "## This notebook is an update of this [work](https://www.kaggle.com/humananalog/inference-demo). \n",
    "## If it is useful for you, please consider your upvote.\n",
    "\n",
    "This is the kernel I’ve used for my recent submissions. It takes about 5-6 hours on the test set, using only CPU. \n",
    "\n",
    "I’ve provided this kernel because a lot of people have problems making submissions. This method works and has never errored out for me. (Although I haven't tried making a submission using the GPU yet -- so no guarantees there.)\n",
    "\n",
    "It uses BlazeFace for face extraction (see also [my BlazeFace kernel](https://www.kaggle.com/humananalog/starter-blazeface-pytorch)) and ResNeXt50 as the classifier model.\n",
    "\n",
    "We take the average prediction over 17 frames from each video. (Why 17? Using more frames makes the kernel slower, but doesn't appear to improve the score much. I used an odd number so we don't always land on even frames.)\n",
    "\n",
    "**Please use this kernel only to learn from...** Included is the checkpoint for a ResNeXt50 model that hasn't really been trained very well yet. I'm sure you can improve on it by training your own model!\n",
    "\n",
    "You could use the included trained weights to get yourself an easy top-50 score on the leaderboard (as of 24 Jan 2020) but it’s nicer to use it as a starting point for your own work. :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_PATH = Path('../input/deepfake-detection-challenge/train_sample_videos/') \n",
    "# TEST_PATH = Path('../input/deepfake-detection-challenge/test_videos/') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.3.1\n",
      "CUDA version: 10.0.130\n",
      "cuDNN version: 7605\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/blazeface-pytorch\")\n",
    "sys.path.insert(0, \"../input/deepfakes-inference-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blazeface import BlazeFace\n",
    "facedet = BlazeFace().to(gpu)\n",
    "facedet.load_weights(\"../input/blazeface-pytorch/blazeface.pth\")\n",
    "facedet.load_anchors(\"../input/blazeface-pytorch/anchors.npy\")\n",
    "_ = facedet.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.read_video_1 import VideoReader\n",
    "from helpers.face_extract_1 import FaceExtractor\n",
    "\n",
    "frames_per_video = 25  \n",
    "video_reader = VideoReader()\n",
    "video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n",
    "face_extractor = FaceExtractor(video_read_fn, facedet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224    # 224 x 224 x 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-be1ecc93a295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TEST DISPLAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'aagfhgtpmv.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mface_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_only_best_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'faces'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TRAIN_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "# TEST DISPLAY\n",
    "faces = face_extractor.process_video(TRAIN_PATH/'aagfhgtpmv.mp4', margin=0.6)\n",
    "face_extractor.keep_only_best_face(faces)\n",
    "\n",
    "face = faces[2]['faces'][0]\n",
    "\n",
    "# resized_face = isotropically_resize_image(face, input_size)\n",
    "# resized_face = make_square_image(resized_face)\n",
    "\n",
    "print(face.shape)\n",
    "\n",
    "plt.imshow(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'aagfhgtpmv.mp4_20.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-53b766fe7729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aagfhgtpmv.mp4_20.jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aagfhgtpmv.mp4_20.jpeg'"
     ]
    }
   ],
   "source": [
    "im = Image.open(open(\"aagfhgtpmv.mp4_20.jpeg\", 'rb'))\n",
    "plt.imshow(np.array(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Code here (with different chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_PATH = Path('../input/deepfake-detection-challenge/test_videos/') \n",
    "\n",
    "SOURCE_PATH=Path('data/dfdc_train_part_24/')\n",
    "OUTPUT_PATH = Path('data/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anijjqtfth.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qbwwpvgyhh.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zffofixoeh.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bjdtgkmvza.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rkbynalsjc.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qbwwpvgyhh.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kyknzgpgvh.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hyhczxthrs.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lklxnnznwk.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>sxjdqerkfp.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fxfxrgntdt.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>ggltfenzwo.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftmdkroplr.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>dcrkfowrrh.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uvjevytnqy.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ieybeoxyyd.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>gstyhbnxwx.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etisprvjae.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>vcwjvigiyf.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  split        original\n",
       "anijjqtfth.mp4  FAKE  train  qbwwpvgyhh.mp4\n",
       "zffofixoeh.mp4  FAKE  train  bjdtgkmvza.mp4\n",
       "rkbynalsjc.mp4  FAKE  train  qbwwpvgyhh.mp4\n",
       "kyknzgpgvh.mp4  FAKE  train  hyhczxthrs.mp4\n",
       "lklxnnznwk.mp4  FAKE  train  sxjdqerkfp.mp4\n",
       "...              ...    ...             ...\n",
       "fxfxrgntdt.mp4  FAKE  train  ggltfenzwo.mp4\n",
       "ftmdkroplr.mp4  FAKE  train  dcrkfowrrh.mp4\n",
       "uvjevytnqy.mp4  REAL  train             NaN\n",
       "ieybeoxyyd.mp4  FAKE  train  gstyhbnxwx.mp4\n",
       "etisprvjae.mp4  FAKE  train  vcwjvigiyf.mp4\n",
       "\n",
       "[2786 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_data = pd.read_json(SOURCE_PATH/'metadata.json').T\n",
    "train_sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAFcCAYAAABiLOewAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcmUlEQVR4nO3de5hlV1kn4N9HAkbuiWkYCCEBJo8aFBmIEGXk8iCQgEzCCEJEaRAnoqAoOE5EkIuieIFREMEIkXCRiyIShCGEKCoKQpMJAQYY2iQkbWdIQzAkgMjlmz/OLnJSXdXd1V1dlVX1vs9znjpn7bX3/s6uSqp/tdZep7o7AAAAjOVG610AAAAAKyfMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOYCDrKpeXlXPWqVj3bGqrq2qQ6bX76mqn1yNY0/H+19VtXW1jreC8/56VX22qv7fKh7z2Krqqjp0rfatqmdU1StWer49HO/SqvrB1TreaqmqO1fVtavdF4CVEeYADsD0j+0vV9U1VfWvVfWPVfWkqvrm/1+7+0nd/Wv7eKw9/sO9uy/r7pt399dXofbnVNVrFx3/5O4++0CPvcI6jk7y9CTHd/d/WGL7/atqx1rWtL+6+ze6e7/CdVW9qqp+fbVrmvsDwMKjq+qLc69/YKXH7O6Lu/vmq913pab39pbpDwFXV9VHqurH93Hf91bV4w9GXQBrZcV/rQRgNw/v7ndX1a2S3C/J7ye5d5InrOZJqurQ7v7aah7zBuKYJJ/r7ivXu5CNqLsvS/LNMFVVneR7unv7cvtU1SGr8QeDNfC6JB9I8tgk/57kbkm2rGtFAGvIyBzAKunuq7v7nCSPTrK1qr4ruf6IS1UdWVV/NY3iXVVVf19VN6qq1yS5Y5K3TaMlvzQ31e+JVXVZkr9eZvrfXarqA9PIxFur6ojpXLuNaC2M/lXVSUmekeTR0/k+PG3/5rTNqa5nVtWnq+rKqnr1FFjnpyFurarLppGRX1nu2lTVrab9d03He+Z0/B9Mcl6S2091vGol17yqHlZV/7uqvlBVl1fVc5bo9hNVtbOqrqiqp8/te6OqOqOq/rmqPldVb1q4dkuc5/FVdfE0AntJVT12mX7fHO1cyTWqqtMzCyS/NF2Ht81tvntVXTR9f99YVYfN7fdDVXXh3Kjw3fZ60ZY+/2ur6qVV9c6q+mKSH6iq/zId+5qp/mfN9f+PUyhceP3eqnruVMM103GOWGnfafsT5q7XM6pqR1Xdf5nSvzfJn3T3l7r7a919QXefO3es+1TV+6frc2FV3Xdq/60k35fk5dP1/r39uW4A602YA1hl3f2BJDuSLDV97enTti1JbptZoOru/vEkl2U2ynfz7v7tuX3ul+Q7kzxkmVM+LslPJLl9kq8lefE+1PjOJL+R5I3T+b5niW6Pnx4PSHLnzEZ3/mBRn/+c5NuTPDDJr1bVdy5zypckudV0nPtNNT+hu9+d5OQkO6c6Hr+32hf54nSsWyd5WJKfrqpTF/V5QJLjkjw4yRl13VTWn0ty6lTP7ZN8PslLF5+gqm6W2TU9ubtvkeT7k1y4ghr3eo26+8zMRpl+e7oOD5/b/CNJTkpyp8xGnh4/1XWPJGcl+akk35bkj5KcU1XfsoLa5v1okucmuUWS9yW5NsmPZfZ9e3iSp1bVD+1l/62Z/VzfLMnTVtq3qr47s2v9mCRHZfbfyW5Tb+e8P8nLqurRNZuu+03T63OSPDvJEUnOSPIXVfVt3f0/pvf4pOl6//wezgFwgyXMARwcOzP7B+RiX01yuyTHdPdXu/vvu7uX6DfvOd39xe7+8jLbX9PdH+3uLyZ5VpIfqWmBlAP02CQvmu55ujbJLyd5TF1/VPC53f3l7v5wkg8n2S0UTrU8Oskvd/c13X1pkhcm2ad7m/aku9/T3R/p7m9090VJXp9ZOJv33On6fSTJnyQ5bWr/qSS/0t07uvsrSZ6T5JG19KIn30jyXVX1rd19RXd/bAVl7vUa7cWLu3tnd1+V5G1J7j61/7ckf9Td/9TdX5/udfxKkhNXePwFb+nu903X8ivd/dfTz9U3ptrfkN2v7bxXdvenuvtLSf5srs6V9H1Ukr/s7n+cvifP3EvN/zWzUPbsJJ+uqguq6p7TtsclOae7z53ewzszu/4n7eWYAMMQ5gAOjqOSXLVE++8k2Z7kXdO0vTP24ViXr2D7p5PcOMmR+1Tlnt1+Ot78sQ/NbDRlwfzqk1/K3L1Zc45McpMljnXUgRZYVfeuqr+Zpm9eneRJ2f29L74+t5+eH5PkLdMUvH9N8vEkX8/131+mkPzo6dhXVNXbq+o7VlDmvlyj/dn/mCRPX6h/eg9H57r3t1LX+zmrqu+r2bTbhWv7k9nzz9VK3udyfW8/X8d07T+/3EG6+6ru/qXuPj6z79vHkrxl2nxMktMWXZ8Ts//XB+AGR5gDWGVV9b2ZBZX3Lt42jUw9vbvvnNnUtadV1QMXNi9zyL2N3M1PL7tjZqN/n81sCuJN5+o6JNdfHGJvx92Z2T+I54/9tSSf2ct+i312qmnxsf5lhcdZyp9mNpXu6O6+VZKXJ6lFfRZfn53T88szmzp567nHYd29W13T6M6DMhtV/USSP16F2nc7zQr7X57k+Yvqv2l3v36Vzv+GJG/Oddf2Fdn92q62K5LcYeHFNMX18H3Zsbt3ZTbie3TN7u28PLP76eavz826+3cWdlnl2gHWnDAHsEqq6pbTPUVvSPLaaVrf4j4/NC0IUUm+kNlI0MKqgZ/J7J6ylfqxqjq+qm6a5HlJ/nxaifD/JjmsZouE3DizKWvz91N9JsmxNfcxCou8PskvVNWdqurmue4euxWtqDnV8qYkz6+qW1TVMZndI/XaPe95fVV12KJHZXZ/11Xd/W9Vda/M7sVa7FlVddOqumtmK4y+cWp/+VTTMdPxt1TVKUuc97bTYiA3y2wa47W57nu2mlb6/f/jJE+aRierqm42fa9vsUr1zF/bEzO7j+1g+7Mkp1bViVV1k8x+npdVVb9dVXetqkOq6pZJfjrJJ7r76iSvSfKIqnrQtP2wqnpAVS2MzO3vf28ANxjCHMCBe1tVXZPZSMCvJHlRlv9YguOSvDuzQPC+JH/Y3e+Ztv1mkmdOU8J+cQXnf02SV2U2de2wzBb2yPQP2p/JbETlXzIbqZtf3fLPpq+fq6oLljjuWdOx/y7JJUn+LcnPrqCueT87nf/izEYs/3Q6/r46KsmXFz3uktn7e950/X81s9C42N9mNrX1/CS/293vmtp/P7NRvXdN+78/s4+UWOxGmS1cszOzqbP3m8672l6Z5Pjp+/+Xe+vc3dsyu2/uDzKbirg90+Ioq+Snk/zmdG2ekaWv7aqa7nv8hcx+Nncm+dz0+Moyu9w8yVuTXJ3knzObQnnqdKxLkzwis/tId2W2wNDTc92/fX4v103DfNFBeDsAB13t/b57AIC1N422/WtmCwbt7d5RgE3HyBwAcIMxTWm96TS194VJLhDkAJYmzAEANySPyGyK5Y4kx+a6j5IAYBHTLAEAAAZkZA4AAGBAwhwAAMCADl3vAvbkyCOP7GOPPXa9ywAAAFgXH/rQhz7b3VuW2naDDnPHHntstm3btt5lAAAArIuq+vRy20yzBAAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADCgQ9e7AMZ27BlvX+8SYGiXvuBh610CADAoI3MAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABrTXMFdVR1fV31TVx6vqY1X11Kn9iKo6r6o+NX09fGqvqnpxVW2vqouq6h5zx9o69f9UVW09eG8LAABgY9uXkbmvJXl6d39nkhOTPLmqjk9yRpLzu/u4JOdPr5Pk5CTHTY/Tk7wsmYW/JM9Ocu8k90ry7IUACAAAwMrsNcx19xXdfcH0/JokH09yVJJTkpw9dTs7yanT81OSvLpn3p/k1lV1uyQPSXJed1/V3Z9Pcl6Sk1b13QAAAGwSK7pnrqqOTfKfkvxTktt29xXJLPAluc3U7agkl8/ttmNqW64dAACAFdrnMFdVN0/y5iQ/391f2FPXJdp6D+2Lz3N6VW2rqm27du3a1/IAAAA2lX0Kc1V148yC3Ou6+y+m5s9M0yczfb1yat+R5Oi53e+QZOce2q+nu8/s7hO6+4QtW7as5L0AAABsGvuymmUleWWSj3f3i+Y2nZNkYUXKrUneOtf+uGlVyxOTXD1Nwzw3yYOr6vBp4ZMHT20AAACs0KH70Oc+SX48yUeq6sKp7RlJXpDkTVX1xCSXJXnUtO0dSR6aZHuSLyV5QpJ091VV9WtJPjj1e153X7Uq7wIAAGCT2WuY6+73Zun73ZLkgUv07yRPXuZYZyU5ayUFAgAAsLsVrWYJAADADYMwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABrTXMFdVZ1XVlVX10bm251TVv1TVhdPjoXPbfrmqtlfVJ6vqIXPtJ01t26vqjNV/KwAAAJvHvozMvSrJSUu0/8/uvvv0eEeSVNXxSR6T5K7TPn9YVYdU1SFJXprk5CTHJzlt6gsAAMB+OHRvHbr776rq2H083ilJ3tDdX0lySVVtT3Kvadv27r44SarqDVPf/7PiigEAADige+aeUlUXTdMwD5/ajkpy+VyfHVPbcu27qarTq2pbVW3btWvXAZQHAACwce1vmHtZkrskuXuSK5K8cGqvJfr2Htp3b+w+s7tP6O4TtmzZsp/lAQAAbGx7nWa5lO7+zMLzqvrjJH81vdyR5Oi5rndIsnN6vlw7AAAAK7RfI3NVdbu5l49IsrDS5TlJHlNV31JVd0pyXJIPJPlgkuOq6k5VdZPMFkk5Z//LBgAA2Nz2OjJXVa9Pcv8kR1bVjiTPTnL/qrp7ZlMlL03yU0nS3R+rqjdltrDJ15I8ubu/Ph3nKUnOTXJIkrO6+2Or/m4AAAA2iX1ZzfK0JZpfuYf+z0/y/CXa35HkHSuqDgAAgCUdyGqWAAAArBNhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABrTXMFdVZ1XVlVX10bm2I6rqvKr61PT18Km9qurFVbW9qi6qqnvM7bN16v+pqtp6cN4OAADA5rAvI3OvSnLSorYzkpzf3cclOX96nSQnJzluepye5GXJLPwleXaSeye5V5JnLwRAAAAAVm6vYa67/y7JVYuaT0ly9vT87CSnzrW/umfen+TWVXW7JA9Jcl53X9Xdn09yXnYPiAAAAOyj/b1n7rbdfUWSTF9vM7UfleTyuX47prbl2ndTVadX1baq2rZr1679LA8AAGBjW+0FUGqJtt5D++6N3Wd29wndfcKWLVtWtTgAAICNYn/D3Gem6ZOZvl45te9IcvRcvzsk2bmHdgAAAPbD/oa5c5IsrEi5Nclb59ofN61qeWKSq6dpmOcmeXBVHT4tfPLgqQ0AAID9cOjeOlTV65PcP8mRVbUjs1UpX5DkTVX1xCSXJXnU1P0dSR6aZHuSLyV5QpJ091VV9WtJPjj1e153L15UBQAAgH201zDX3acts+mBS/TtJE9e5jhnJTlrRdUBAACwpNVeAAUAAIA1IMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCADijMVdWlVfWRqrqwqrZNbUdU1XlV9anp6+FTe1XVi6tqe1VdVFX3WI03AAAAsBmtxsjcA7r77t19wvT6jCTnd/dxSc6fXifJyUmOmx6nJ3nZKpwbAABgUzoY0yxPSXL29PzsJKfOtb+6Z96f5NZVdbuDcH4AAIAN70DDXCd5V1V9qKpOn9pu291XJMn09TZT+1FJLp/bd8fUdj1VdXpVbauqbbt27TrA8gAAADamQw9w//t0986quk2S86rqE3voW0u09W4N3WcmOTNJTjjhhN22AwAAcIAjc929c/p6ZZK3JLlXks8sTJ+cvl45dd+R5Oi53e+QZOeBnB8AAGCz2u8wV1U3q6pbLDxP8uAkH01yTpKtU7etSd46PT8nyeOmVS1PTHL1wnRMAAAAVuZAplneNslbqmrhOH/a3e+sqg8meVNVPTHJZUkeNfV/R5KHJtme5EtJnnAA5wYAANjU9jvMdffFSb5nifbPJXngEu2d5Mn7ez4AAACuczA+mgAAAICD7EBXswQAWFfHnvH29S4BhnbpCx623iWwn4zMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQGse5qrqpKr6ZFVtr6oz1vr8AAAAG8GahrmqOiTJS5OcnOT4JKdV1fFrWQMAAMBGsNYjc/dKsr27L+7uf0/yhiSnrHENAAAAwzt0jc93VJLL517vSHLv+Q5VdXqS06eX11bVJ9eoNtiojkzy2fUugqXVb613BQAHnd9DN3B+F93gHbPchrUOc7VEW1/vRfeZSc5cm3Jg46uqbd19wnrXAcDm5PcQHDxrPc1yR5Kj517fIcnONa4BAABgeGsd5j6Y5LiqulNV3STJY5Kcs8Y1AAAADG9Np1l299eq6ilJzk1ySJKzuvtja1kDbEKmLQOwnvwegoOkunvvvQAAALhBWfMPDQcAAODACXMAAAADEuYAAAAGJMwBAHDQVdXPr3cNsNEIc7CBVNXvzT1/6qJtr1rzggDgOk9b7wJgoxHmYGO579zzrYu23W0tCwGARWq9C4CNRpiDjaWWeQ4A683nYcEqW9MPDQcOuhtV1eGZ/aFm4flCqDtk/coCYDOoqmuydGirJDdd43Jgw/Oh4bCBVNWlSb6RpUflurvvvLYVAQBwsAhzsElU1eHd/fn1rgOAzaWqbpbk1CQ/2t0PW+96YCNxzxxsIFX1imXa75Dk79e4HAA2qaq6SVWdWlVvSnJFkh9M8vJ1Lgs2HGEONpYbV9Vrq+qb/21X1fGZBbnfXb+yANgMqupBVXVWkkuSPDLJa5Jc1d1P6O63rW91sPGYZgkbSFVVkj9KcniSxyS5d5I3JnlSd799PWsDYOOrqm9k9gfEx3f3JVPbxe7ZhoPDapawgfTsrzOnV9XvJ3lPkmOSPKq737+uhQGwWdwzsz8mvruqLk7yhlhNGQ4aI3OwgVTVSzJbErqS/GiSC5J8fGF7d//cOpUGwCZTVfdJclqSH05yYZK3dPeZ61sVbCzCHGwgVbV1T9u7++y1qgUAkmS6j/tBSR7d3T+x3vXARmKaJWwgy4W1qjosycPXuBwANpmq+rHufu30/D7d/Q/d/Y0k51bVcetcHmw4VrOEDaqqDqmqk6vq1Uk+neTR610TABve0+aev2TRNqNysMqMzMEGU1X3zex+uYcl+UCS+yS5U3d/aV0LA2AzqGWeL/UaOEDCHGwgVbUjyWVJXpbkv3f3NVV1iSAHwBrpZZ4v9Ro4QMIcbCxvTnJqZlMqv15Vb41fngCsne+oqosyG4W7y/Q802ufNQerzGqWsMFMHxz+gMyWg35oklsmeWKSd3T3tetZGwAbW1Uds6ft3f3ptaoFNgNhDjawqrpxkpMyC3YP7u4j17kkADahqjokyWO6+3XrXQtsJMIcbCBVdcfuvmyZbd/a3V9e65oA2Dyq6pZJnpzkqCTnJDkvyVOS/GKSC7v7lHUsDzYcYQ42kKq6oLvvMT1/c3f/8HrXBMDmMd2r/fkk70vywCSHJ7lJkqd294XrWRtsRBZAgY1lftlnN5oDsNbu3N3fnSRV9Yokn01yx+6+Zn3Lgo3Jh4bDxrKnJaEB4GD76sKT7v56kksEOTh4TLOEDaSqvp7ki5mN0H1rkoXPl6sk3d23XK/aANj45n4PJdf/XeT3EBwEwhwAAMCATLMEAAAYkDAHAAAwIGEOgE2nqq7dy/Zjq+qjKzzmq6rqkQdWGQDsO2EOAABgQMIcAJtWVd28qs6vqguq6iNVdcrc5kOr6uyquqiq/ryqbjrtc8+q+tuq+lBVnVtVt1un8gHY5IQ5ADazf0vyiO6+R5IHJHlhVdW07duTnNndd0vyhSQ/U1U3TvKSJI/s7nsmOSvJ89ehbgDIoetdAACso0ryG1V13yTfSHJUkttO2y7v7n+Ynr82yc8leWeS70py3pT5DklyxZpWDAATYQ6AzeyxSbYkuWd3f7WqLk1y2LRt8Qexdmbh72Pd/X1rVyIALM00SwA2s1sluXIKcg9IcszctjtW1UJoOy3Je5N8MsmWhfaqunFV3XVNKwaAiTAHwGb2uiQnVNW2zEbpPjG37eNJtlbVRUmOSPKy7v73JI9M8ltV9eEkFyb5/jWuGQCSJNW9eBYJAAAAN3RG5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAAD+v86QO2v58If7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "FAKE    2347\n",
      "REAL     439\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Just a bit of statistics to see how many frames to take\n",
    "train_sample_data.groupby('label')['label'].count().plot(figsize=(15, 5), kind='bar', title='Distribution of Labels in the Training Set')\n",
    "plt.show()\n",
    "\n",
    "print(train_sample_data.groupby('label')['label'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder train\n",
    "if not os.path.exists('data/temp/'):\n",
    "    os.makedirs('data/temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_save_file(input_path, file_name, output_path):\n",
    "    \n",
    "    if not os.path.exists(input_path/file_name):\n",
    "        print(f\"File {input_path/file_name} does not exist\")\n",
    "        return\n",
    "    \n",
    "    faces = face_extractor.process_video(input_path/file_name, margin=0.6)\n",
    "    face_extractor.keep_only_best_face(faces)\n",
    "\n",
    "    i = 0\n",
    "    # TODO: Combine with data to put to different folders :D \n",
    "    for frame_face in faces:        \n",
    "        for face in frame_face[\"faces\"]:    # should only  got 1 here\n",
    "\n",
    "            im = Image.fromarray(face)\n",
    "            im.save( f\"{output_path/file_name}_{i}.jpeg\")\n",
    "            \n",
    "            # increase index\n",
    "            i += 1\n",
    "        \n",
    "# process_save_file('aagfhgtpmv.mp4', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_24\n",
      "data/temp\n"
     ]
    }
   ],
   "source": [
    "print(SOURCE_PATH)\n",
    "print(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2347 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/temp/fake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2347/2347 [1:05:41<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save fake files, get 60 frames per fake videos\n",
    "frames_per_video = 40 \n",
    "\n",
    "working_directory = OUTPUT_PATH/'fake'\n",
    "print(working_directory)\n",
    "\n",
    "# Create folder train\n",
    "if not os.path.exists(working_directory):\n",
    "    os.makedirs(working_directory)\n",
    "\n",
    "fake_files = train_sample_data[train_sample_data['label'] == 'FAKE']\n",
    "    \n",
    "for file in tqdm(fake_files.index): \n",
    "    process_save_file(SOURCE_PATH, file, working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/temp/real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [49:23<00:00,  6.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save real files, get 240 frames per real videos\n",
    "frames_per_video = 240 \n",
    "\n",
    "working_directory = OUTPUT_PATH/'real'\n",
    "print(working_directory)\n",
    "\n",
    "# Create folder train\n",
    "if not os.path.exists(working_directory):\n",
    "    os.makedirs(working_directory)\n",
    "\n",
    "real_files = train_sample_data[train_sample_data['label'] == 'REAL']\n",
    "    \n",
    "for file in tqdm(real_files.index): \n",
    "    process_save_file(SOURCE_PATH, file, working_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
